{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35354cd",
   "metadata": {},
   "source": [
    "# Lightweight Fine-Tuning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560fb3ff",
   "metadata": {},
   "source": [
    "TODO: In this cell, describe your choices for each of the following\n",
    "\n",
    "* PEFT technique: \n",
    "* Model: \n",
    "* Evaluation approach: \n",
    "* Fine-tuning dataset: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d76bb",
   "metadata": {},
   "source": [
    "## Loading and Evaluating a Foundation Model\n",
    "\n",
    "TODO: In the cells below, load your chosen pre-trained Hugging Face model and evaluate its performance prior to fine-tuning. This step includes loading an appropriate tokenizer and dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bf1c4c",
   "metadata": {},
   "source": [
    "For this project, we have selected the **SST2 dataset** from HuggingFace:\n",
    "\n",
    "https://huggingface.co/datasets/sst2\n",
    "\n",
    ", that contains **sentences of comments from movies and sentiment annotations from humans**, provided by the **Stanford Sentiment Treebank**. In this dataset, we have two subsets, that we will use for this project:\n",
    "\n",
    "- **Train subset**, with 67679 samples made by secuences with two labels 0 (negative) and 1(positive)\n",
    "\n",
    "- **Validation subset**, with 872 samples made by secuences with two labels 0 (negative) and 1(positive)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f551c63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2ForSequenceClassification, GPT2Tokenizer, Trainer, TrainingArguments\n",
    "from transformers import DataCollatorWithPadding, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f02659a",
   "metadata": {},
   "source": [
    "#### Load the dataset and obtain statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4935cb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Stanford Sentiment Treebank dataset\n",
    "# See: https://huggingface.co/datasets/sst2\n",
    "\n",
    "# Define the splits we want to load (training and testing)\n",
    "splits = [\"train\", \"validation\"]\n",
    "# Load the SST-2 dataset splits using a dictionary comprehension.\n",
    "# 'load_dataset' function fetches the dataset from Hugging Face's dataset repository.\n",
    "# 'glue' is the broader dataset collection, 'sst2' is the specific dataset for sentiment analysis.\n",
    "# Iterating over the splits list to load both training and testing sets.\n",
    "dataset = {split: load_dataset(\"glue\", \"sst2\", split=split) for split in splits}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdcbf814",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_statistics_subset(dataset, name_subset):\n",
    "    \"\"\"\n",
    "    A function for obtaining some statistics in a sunset of a HuggingFace dataset\n",
    "    :dataset: A Hugging Face dataset object\n",
    "    :name_subset: A string with the name of the subset\n",
    "    \n",
    "    :returns: No return\n",
    "    \"\"\"\n",
    "    # print number of samples in subset\n",
    "    print('Number of samples of', name_subset,'subset:',dataset[name_subset].num_rows)\n",
    "    # print maximum length of sequence in the subset\n",
    "    print('Max length of sentence in', name_subset, 'subset', max(len(sentence) for sentence in dataset[name_subset]['sentence']))\n",
    "    # print minimum length of sequence in the subset\n",
    "    print('Min length of sentence in', name_subset, 'subset', min(len(sentence) for sentence in dataset[name_subset]['sentence']))\n",
    "    # print labels in the subset\n",
    "    print('Labels in', name_subset,':', set(dataset[name_subset]['label']))\n",
    "    # print percentages of each label\n",
    "    print('Percentages for each label in subset:')\n",
    "    # compute frequencies for each label in the dataset\n",
    "    frequencies = {x: dataset[name_subset]['label'].count(x) for x in set(dataset[name_subset]['label'])}\n",
    "    # compute percentages\n",
    "    percentages = {x: (count / dataset[name_subset].num_rows) * 100 for x, count in frequencies.items()}\n",
    "    # loop over the keys in percentages and print values\n",
    "    for key, value in percentages.items():\n",
    "        print('- Label',key,':',round(value,2),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a29a30d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples of train subset: 67349\n",
      "Max length of sentence in train subset 268\n",
      "Min length of sentence in train subset 2\n",
      "Labels in train : {0, 1}\n",
      "Percentages for each label in subset:\n",
      "- Label 0 : 44.22 %\n",
      "- Label 1 : 55.78 %\n"
     ]
    }
   ],
   "source": [
    "# obtain statstics for train subset\n",
    "compute_statistics_subset(dataset=dataset, name_subset='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf4158a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples of validation subset: 872\n",
      "Max length of sentence in validation subset 244\n",
      "Min length of sentence in validation subset 6\n",
      "Labels in validation : {0, 1}\n",
      "Percentages for each label in subset:\n",
      "- Label 0 : 49.08 %\n",
      "- Label 1 : 50.92 %\n"
     ]
    }
   ],
   "source": [
    "# obtain staristics for validation subset\n",
    "compute_statistics_subset(dataset=dataset, name_subset='validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c5e966",
   "metadata": {},
   "source": [
    "#### Load the tokenizer and tokenize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64cc9381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7259977d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set EOS (end of sentence) TOKEN as PAD TOKEN\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2647aa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    \"\"\"Preprocess the imdb dataset by returning tokenized examples.\n",
    "    :examples:\n",
    "    \n",
    "    :returns:\n",
    "    \"\"\"\n",
    "    # convert the text data in a list of tokens using tokenizer, truncating\n",
    "    # the text to the maximum lenght and pad shorter sequences to a uniform lenght\n",
    "    # return the result\n",
    "    return tokenizer(examples['sentence'], padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f28c4a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty dictionary to store the tokenized datasets.\n",
    "tokenized_ds = {}\n",
    "# Iterate over each data split ('train' and 'test').\n",
    "for split in splits:\n",
    "    # Apply the preprocess_function to the dataset corresponding to the current split.\n",
    "    # The 'map' function applies the preprocess_function to each example in the dataset.\n",
    "    # 'batched=True' allows processing multiple examples at once for efficiency.\n",
    "    tokenized_ds[split] = dataset[split].map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "019b9f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hide new secretions from the parental units \n",
      "[24717, 649, 3200, 507, 422, 262, 21694, 4991, 220, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]\n"
     ]
    }
   ],
   "source": [
    "# print a sample of sentence and its tokenization in train subset\n",
    "print(tokenized_ds[\"train\"][0]['sentence'])\n",
    "print(tokenized_ds[\"train\"][0][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5176b07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it 's a charming and often affecting journey . \n",
      "[270, 705, 82, 257, 23332, 290, 1690, 13891, 7002, 764, 220, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]\n"
     ]
    }
   ],
   "source": [
    "# print a sample of sentence and its tokenization in validation subset\n",
    "print(tokenized_ds[\"validation\"][0]['sentence'])\n",
    "print(tokenized_ds[\"validation\"][0][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e203161",
   "metadata": {},
   "source": [
    "#### Load the model and freeze base parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "357a83f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained model 'gpt-2' for sequence classification.\n",
    "# This model is designed for tasks like sentiment analysis where each sequence (like a sentence)\n",
    "# is classified into categories (like positive/negative).\n",
    "# here, we specify the number of labels (2 for sentiment classification),\n",
    "# id2label and label2id corresponding to POSITIVE and NEGATIVE labels\n",
    "model = GPT2ForSequenceClassification.from_pretrained('gpt2',\n",
    "                                                      num_labels=2,\n",
    "                                                      id2label={0: \"NEGATIVE\", 1: \"POSITIVE\"},\n",
    "                                                      label2id={\"NEGATIVE\": 0, \"POSITIVE\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b1c6824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model's pad token id to match the tokenizer's pad token id\n",
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1dcd48d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all the parameters of the base model\n",
    "# Iterate over all the parameters of the base model.\n",
    "for param in model.base_model.parameters():\n",
    "    # freeze the base model disabling the gradient calculations for each parameter\n",
    "    # in the base model of \"gpt2\" model\n",
    "    # Set 'requires_grad' to False to freeze the parameters of the base model.\n",
    "    # Freezing prevents the weights of these layers from being updated during training.\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2c00e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2ForSequenceClassification(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(50257, 768)\n",
      "    (wpe): Embedding(1024, 768)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-11): 12 x GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (score): Linear(in_features=768, out_features=2, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# check model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4cf5e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=768, out_features=2, bias=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The 'model.score' is the classification head that will be trained to adapt \n",
    "# the base model for our specific task (sentiment analysis in this case).\n",
    "model.score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20ee93c",
   "metadata": {},
   "source": [
    "#### Train the model using Trainer from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51faa1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"\n",
    "    Function for compute tha accuracy metric\n",
    "    :eval_pred: a tuple with predictions and labels\n",
    "    \n",
    "    :returns: a dictionary with the mean accuracy\n",
    "    \"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "    # Convert the predictions to discrete labels by taking the argmax,\n",
    "    # which is the index of the highest value in the prediction (logits).\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    # Calculate and return the accuracy as the mean of the instances where\n",
    "    # predictions match the true labels.\n",
    "    return {\"accuracy\": (predictions == labels).mean()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef5382bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The HuggingFace Trainer class handles the training and eval loop for PyTorch for us.\n",
    "# Initialize the Trainer, a high-level API for training transformer models.\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"./data/sentiment_analysis\", # Directory where the model outputs will be saved.\n",
    "        learning_rate=2e-5, # Learning rate for the optimizer.\n",
    "        # Reduce the batch size if you don't have enough memory\n",
    "        per_device_train_batch_size=16, # Batch size for training per device.\n",
    "        per_device_eval_batch_size=16, # Batch size for evaluation per device.\n",
    "        num_train_epochs=1, # Number of training epochs.\n",
    "        weight_decay=0.01, # Weight decay for regularization.\n",
    "        evaluation_strategy=\"epoch\", # Evaluation is performed at the end of each epoch.\n",
    "        save_strategy=\"epoch\", # Model is saved at the end of each epoch.\n",
    "        load_best_model_at_end=True, # Load the best model at the end of training.\n",
    "    ),\n",
    "    train_dataset=tokenized_ds[\"train\"], # The tokenized training dataset.\n",
    "    eval_dataset=tokenized_ds[\"validation\"], # The tokenized evaluation dataset.\n",
    "    tokenizer=tokenizer, # The tokenizer used for encoding the data.\n",
    "    # Data collator that will dynamically pad the batches during training.\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics, # Function to compute metrics during evaluation.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b029f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='4210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/4210 04:50, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.645600</td>\n",
       "      <td>0.641169</td>\n",
       "      <td>0.719037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4210, training_loss=0.6930750975982594, metrics={'train_runtime': 291.336, 'train_samples_per_second': 231.173, 'train_steps_per_second': 14.451, 'total_flos': 2161131327553536.0, 'train_loss': 0.6930750975982594, 'epoch': 1.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start the training process.\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabdcb02",
   "metadata": {},
   "source": [
    "#### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "adbefabd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6411694884300232,\n",
       " 'eval_accuracy': 0.7190366972477065,\n",
       " 'eval_runtime': 3.385,\n",
       " 'eval_samples_per_second': 257.603,\n",
       " 'eval_steps_per_second': 16.248,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the performance of the model on the validation set\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e46c81",
   "metadata": {},
   "source": [
    "#### View the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "329b0288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>it 's a charming and often affecting journey .</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unflinchingly bleak and desperate</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allows us to hope that nolan is poised to emba...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the acting , costumes , music , cinematography...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it 's slow -- very , very slow .</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>although laced with humor and a few fanciful t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a sometimes tedious film .</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>or doing last year 's taxes with your ex-wife .</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>you do n't have to know about music to appreci...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>in exactly 89 minutes , most of which passed a...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  label  predicted_label\n",
       "0    it 's a charming and often affecting journey .       1                1\n",
       "1                 unflinchingly bleak and desperate       0                1\n",
       "2  allows us to hope that nolan is poised to emba...      1                1\n",
       "3  the acting , costumes , music , cinematography...      1                1\n",
       "4                  it 's slow -- very , very slow .       0                1\n",
       "5  although laced with humor and a few fanciful t...      1                0\n",
       "6                        a sometimes tedious film .       0                1\n",
       "7   or doing last year 's taxes with your ex-wife .       0                1\n",
       "8  you do n't have to know about music to appreci...      1                1\n",
       "9  in exactly 89 minutes , most of which passed a...      0                1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the tokenized test dataset to a pandas DataFrame\n",
    "df = pd.DataFrame(tokenized_ds[\"validation\"])\n",
    "# Select only the 'sentence' and 'label' columns for simplicity\n",
    "df = df[[\"sentence\", \"label\"]]\n",
    "# Use the trained model to make predictions on the validation dataset\n",
    "predictions = trainer.predict(tokenized_ds[\"validation\"])\n",
    "# Convert the raw prediction logits to discrete labels (0 or 1 in our case)\n",
    "# The argmax function is used to select the index (label) with the highest prediction score.\n",
    "df[\"predicted_label\"] = np.argmax(predictions[0], axis=1)\n",
    "# Display the first two rows of the dataframe to check the data.\n",
    "# This shows the actual and predicted labels alongside the sentences.\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fb0622",
   "metadata": {},
   "source": [
    "#### Look at some incorrect predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c73d978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unflinchingly bleak and desperate</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it 's slow -- very , very slow .</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>although laced with humor and a few fanciful touches , the film is a refreshingly serious look at young women .</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a sometimes tedious film .</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>or doing last year 's taxes with your ex-wife .</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>in exactly 89 minutes , most of which passed as slowly as if i 'd been sitting naked on an igloo , formula 51 sank from quirky to jerky to utter turkey .</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>we root for ( clara and paul ) , even like them , though perhaps it 's an emotion closer to pity .</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>the emotions are raw and will strike a nerve with anyone who 's ever had family trauma .</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>in its best moments , resembles a bad high school production of grease , without benefit of song .</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>the iditarod lasts for days - this just felt like it did .</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                      sentence  \\\n",
       "1                                                                                                                           unflinchingly bleak and desperate    \n",
       "4                                                                                                                            it 's slow -- very , very slow .    \n",
       "5                                             although laced with humor and a few fanciful touches , the film is a refreshingly serious look at young women .    \n",
       "6                                                                                                                                  a sometimes tedious film .    \n",
       "7                                                                                                             or doing last year 's taxes with your ex-wife .    \n",
       "9   in exactly 89 minutes , most of which passed as slowly as if i 'd been sitting naked on an igloo , formula 51 sank from quirky to jerky to utter turkey .    \n",
       "13                                                         we root for ( clara and paul ) , even like them , though perhaps it 's an emotion closer to pity .    \n",
       "16                                                                   the emotions are raw and will strike a nerve with anyone who 's ever had family trauma .    \n",
       "19                                                         in its best moments , resembles a bad high school production of grease , without benefit of song .    \n",
       "21                                                                                                 the iditarod lasts for days - this just felt like it did .    \n",
       "\n",
       "    label  predicted_label  \n",
       "1       0                1  \n",
       "4       0                1  \n",
       "5       1                0  \n",
       "6       0                1  \n",
       "7       0                1  \n",
       "9       0                1  \n",
       "13      1                0  \n",
       "16      1                0  \n",
       "19      0                1  \n",
       "21      0                1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set a pandas display option to show the full content of each column in the DataFrame.\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "# Filter the DataFrame to only include rows where the model's predictions do not match the actual labels.\n",
    "df[df[\"label\"] != df[\"predicted_label\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d52a229",
   "metadata": {},
   "source": [
    "## Performing Parameter-Efficient Fine-Tuning\n",
    "\n",
    "TODO: In the cells below, create a PEFT model from your loaded model, run a training loop, and save the PEFT model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5775fadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97013657",
   "metadata": {},
   "source": [
    "#### Load GPT-2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "894046c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained model 'gpt-2' for sequence classification.\n",
    "# This model is designed for tasks like sentiment analysis where each sequence (like a sentence)\n",
    "# is classified into categories (like positive/negative).\n",
    "# here, we specify the number of labels (2 for sentiment classification),\n",
    "# id2label and label2id corresponding to POSITIVE and NEGATIVE labels\n",
    "model = GPT2ForSequenceClassification.from_pretrained('gpt2',\n",
    "                                                      num_labels=2,\n",
    "                                                      id2label={0: \"NEGATIVE\", 1: \"POSITIVE\"},\n",
    "                                                      label2id={\"NEGATIVE\": 0, \"POSITIVE\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4d4c908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model's pad token id to match the tokenizer's pad token id\n",
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca03195",
   "metadata": {},
   "source": [
    "#### Configure LoRA using PETF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b47abf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PEFT Config for LoRA\n",
    "config = LoraConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "717c5776",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/peft/tuners/lora.py:475: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Convert the GPT-2 model into a PEFT model\n",
    "lora_model = get_peft_model(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ac06b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 294,912 || all params: 124,736,256 || trainable%: 0.236428452686603\n"
     ]
    }
   ],
   "source": [
    "# print the number of trainable parameters in LoRA\n",
    "lora_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735648f8",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f71037aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename 'label' to 'labels' to match the Trainer's expectation\n",
    "tokenized_ds[\"train\"] = tokenized_ds[\"train\"].map(lambda e: {'labels': e['label']}, batched=True, remove_columns=['label'])\n",
    "tokenized_ds[\"validation\"] = tokenized_ds[\"validation\"].map(lambda e: {'labels': e['label']}, batched=True, remove_columns=['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7fc4307b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_ds[\"train\"].set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "tokenized_ds[\"validation\"].set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "41bb21d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=lora_model,  # Make sure to pass the PEFT model here\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"./data/sentiment_analysis_lora\",\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=32,\n",
    "        per_device_eval_batch_size=32,\n",
    "        num_train_epochs=1,\n",
    "        weight_decay=0.01,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        logging_dir='./logs',  # If you want to log metrics and/or losses during training\n",
    "    ),\n",
    "    train_dataset=tokenized_ds[\"train\"],\n",
    "    eval_dataset=tokenized_ds[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer, padding=True, max_length=512),\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f6fc87f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Invalid key: 65300 is out of bounds for size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Start the training process\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1555\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1553\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1554\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1555\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1560\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1815\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1812\u001b[0m     rng_to_sync \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1814\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1815\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(epoch_iterator):\n\u001b[1;32m   1816\u001b[0m     total_batched_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1817\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m rng_to_sync:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/data_loader.py:384\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# We iterate one batch ahead to check when we are at the end\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 384\u001b[0m     current_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/arrow_dataset.py:2807\u001b[0m, in \u001b[0;36mDataset.__getitems__\u001b[0;34m(self, keys)\u001b[0m\n\u001b[1;32m   2805\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitems__\u001b[39m(\u001b[38;5;28mself\u001b[39m, keys: List) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List:\n\u001b[1;32m   2806\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Can be used to get a batch using a list of integers indices.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2807\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2808\u001b[0m     n_examples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch[\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(batch))])\n\u001b[1;32m   2809\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [{col: array[i] \u001b[38;5;28;01mfor\u001b[39;00m col, array \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems()} \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_examples)]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/arrow_dataset.py:2803\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2801\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[1;32m   2802\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/arrow_dataset.py:2787\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[0;34m(self, key, **kwargs)\u001b[0m\n\u001b[1;32m   2785\u001b[0m format_kwargs \u001b[38;5;241m=\u001b[39m format_kwargs \u001b[38;5;28;01mif\u001b[39;00m format_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m   2786\u001b[0m formatter \u001b[38;5;241m=\u001b[39m get_formatter(format_type, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mfeatures, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[0;32m-> 2787\u001b[0m pa_subtable \u001b[38;5;241m=\u001b[39m \u001b[43mquery_table\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_indices\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_indices\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   2788\u001b[0m formatted_output \u001b[38;5;241m=\u001b[39m format_table(\n\u001b[1;32m   2789\u001b[0m     pa_subtable, key, formatter\u001b[38;5;241m=\u001b[39mformatter, format_columns\u001b[38;5;241m=\u001b[39mformat_columns, output_all_columns\u001b[38;5;241m=\u001b[39moutput_all_columns\n\u001b[1;32m   2790\u001b[0m )\n\u001b[1;32m   2791\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/formatting/formatting.py:583\u001b[0m, in \u001b[0;36mquery_table\u001b[0;34m(table, key, indices)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    582\u001b[0m     size \u001b[38;5;241m=\u001b[39m indices\u001b[38;5;241m.\u001b[39mnum_rows \u001b[38;5;28;01mif\u001b[39;00m indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m table\u001b[38;5;241m.\u001b[39mnum_rows\n\u001b[0;32m--> 583\u001b[0m     \u001b[43m_check_valid_index_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[38;5;66;03m# Query the main table\u001b[39;00m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/formatting/formatting.py:536\u001b[0m, in \u001b[0;36m_check_valid_index_key\u001b[0;34m(key, size)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Iterable):\n\u001b[1;32m    535\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(key) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 536\u001b[0m         \u001b[43m_check_valid_index_key\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m         _check_valid_index_key(\u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mmin\u001b[39m(key)), size\u001b[38;5;241m=\u001b[39msize)\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/formatting/formatting.py:526\u001b[0m, in \u001b[0;36m_check_valid_index_key\u001b[0;34m(key, size)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m    525\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (key \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;241m+\u001b[39m size \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (key \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m size):\n\u001b[0;32m--> 526\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid key: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is out of bounds for size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mslice\u001b[39m):\n",
      "\u001b[0;31mIndexError\u001b[0m: Invalid key: 65300 is out of bounds for size 0"
     ]
    }
   ],
   "source": [
    "# Start the training process\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24d4bb8",
   "metadata": {},
   "source": [
    "#### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7fe003",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_model.save_pretrained(\"gpt2_lora\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615b12c6",
   "metadata": {},
   "source": [
    "## Performing Inference with a PEFT Model\n",
    "\n",
    "TODO: In the cells below, load the saved PEFT model weights and evaluate the performance of the trained PEFT model. Be sure to compare the results to the results from prior to fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863ec66e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
